name: Mega-Intelligence Virtual AI Engine

on:
  workflow_dispatch:
    inputs:
      instance_names:
        description: '생성할 AI 이름들'
        required: true
        default: 'Security-Deep-Brain, Marketing-Master'
      kb_size_mb:
        description: '지식 베이스 크기 (MB 단위)'
        required: true
        default: '5'

jobs:
  spawn-mega-ai:
    runs-on: ubuntu-latest
    permissions:
      contents: write # 깃허브 저장소에 결과를 커밋하기 위한 권한

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Initialize OpenClaw
        run: |
          git clone --recursive https://github.com/koreatest12/openclaw.git openclaw_src
          mkdir -p openclaw_src/output
          mkdir -p openclaw_src/knowledge_hub
          cd openclaw_src && npm install --legacy-peer-deps

      # [핵심 개발] 메가바이트 단위의 대용량 지식 데이터 생성 로직
      - name: Generate Mega-Byte Knowledge Base
        run: |
          cd openclaw_src
          SIZE_MB=${{ github.event.inputs.kb_size_mb }}
          IFS=',' read -r -a NAME_ARRAY <<< "${{ github.event.inputs.instance_names }}"
          
          for name in "${NAME_ARRAY[@]}"
          do
            clean_name=$(echo $name | xargs)
            KB_FILE="knowledge_hub/${clean_name}_kb.dat"
            
            echo "[Intelligence Injection] Generating $SIZE_MB MB for $clean_name..."
            
            # 실제 지식 데이터를 시뮬레이션하기 위한 대용량 텍스트 생성 (MB 단위)
            # 고유 페르소나와 전문 용어를 반복 주입하여 용량을 채움
            head -c $(($SIZE_MB * 1024 * 1024)) < /dev/urandom | base64 > "$KB_FILE"
            
            # 파일 상단에 지능 헤더 삽입
            echo -e "AI_NAME: $clean_name\nKNOWLEDGE_TYPE: MASSIVE_DATA\nVERSION: 2026.2.16\n---" > tmp_header
            cat tmp_header "$KB_FILE" > "${KB_FILE}.tmp" && mv "${KB_FILE}.tmp" "$KB_FILE"
            
            # 각 AI 인스턴스 설정
            DEST="cloned_runs/$clean_name"
            mkdir -p "$DEST"
            rsync -av --exclude='cloned_runs' --exclude='node_modules' . "$DEST/"
            ln -s "$(pwd)/node_modules" "$DEST/node_modules"
            
            echo "INSTANCE_NAME=$clean_name" > "$DEST/.env"
            echo "KB_PATH=../../knowledge_hub/${clean_name}_kb.dat" >> "$DEST/.env"
            
            echo "가상 AI [$clean_name] 가동 (지능 로드 중...)"
            cd "$DEST"
            node index.js --load-kb=true > "../../output/${clean_name}_log.txt" 2>&1 &
            cd ../..
          done
          
          sleep 45 # 대용량 데이터 처리를 위한 대기 시간
          wait

      # 생성된 지식 및 결과물을 저장소에 자동 커밋 및 푸시
      - name: Commit & Push Intelligence Data
        run: |
          git config --global user.name "AI-Developer"
          git config --global user.email "ai-dev@example.com"
          mkdir -p results/$(date +%Y-%m-%d)
          cp -r openclaw_src/output/* results/$(date +%Y-%m-%d)/
          cp -r openclaw_src/knowledge_hub/*.dat results/$(date +%Y-%m-%d)/
          git add .
          git commit -m "Add Mega-Intelligence Data for ${{ github.event.inputs.instance_names }}" || echo "No changes to commit"
          git push

      - name: Upload Mega Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mega-intelligence-assets
          path: |
            openclaw_src/output/
            openclaw_src/knowledge_hub/*.dat
