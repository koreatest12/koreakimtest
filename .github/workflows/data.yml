name: "🏦 Teradata FinOps Batch — EchoOps + Audit + Snapshot + Schedule (만전대비 + 대량가상데이터 + 시스템업그레이드)"

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:
  schedule:
    # 매일 15:30 UTC == 한국시간(KST) 새벽 00:30 자동 야간배치
    - cron: "30 15 * * *"

permissions:
  contents: write   # 릴리즈 태그/자산 업로드용 (gh release create)

env:
  ###########################################################################
  # 공통 경로 / 대상 테이블
  ###########################################################################
  DATA_ROOT: /home/runner/td_data

  # 서비스/도메인별 테이블 (Staging -> Final -> Audit)
  TBL_STAGE: STG_DATA
  TBL_FINAL: FINAL_DATA
  TBL_AUDIT: LOAD_AUDIT_LOG

  # 병합 타깃 운영 테이블
  TARGET_TABLE: FINAL_DATA

  ###########################################################################
  # 가상 데이터/품질 기준
  #
  # GEN_ROWS: 이번 배치에서 "생성/적재"한다고 가정하는 가상 레코드 수
  # EXPECTED_ROWCOUNT: 품질 검증 시 기대 로우 수로 사용
  ###########################################################################
  GEN_ROWS: "500000"
  EXPECTED_ROWCOUNT: "500000"

jobs:
  teradata_pipeline_job:
    runs-on: ubuntu-latest

    steps:
      #######################################################################
      # 0. 코드 체크아웃 + 시작 알림
      #######################################################################
      - name: 📥 코드 체크아웃
        uses: actions/checkout@v5

      - name: 📝 워크플로우 시작 로깅
        run: |
          echo "::notice::Teradata 통합 워크플로우 시작 (야간배치/수동실행/Push 공통)."
          echo "::debug::DATA_ROOT=${DATA_ROOT}, TARGET_TABLE=${TARGET_TABLE}, GEN_ROWS=${GEN_ROWS}"

      #######################################################################
      # 0.5 러너 환경 업그레이드(apt update && upgrade 등)
      #     - 네트워크/패키지 레포 이슈로 실패할 수 있으므로 continue-on-error
      #     - 결과는 업그레이드 로그로 남김 (보안/감사 관점에서 중요)
      #######################################################################
      - name: 🔄 러너 패키지 업그레이드 (시스템 업데이트 & 업그레이드)
        continue-on-error: true
        run: |
          set +e
          mkdir -p "${DATA_ROOT}/logs"
          UPG_LOG="${DATA_ROOT}/logs/system_upgrade.log"

          {
            echo "===== SYSTEM UPGRADE START ====="
            date
            echo "--- apt-get update ---"
            sudo apt-get update -y || echo "[WARN] apt-get update 실패"
            echo "--- apt-get upgrade (dist-upgrade) ---"
            sudo apt-get -o Dpkg::Options::="--force-confnew" dist-upgrade -y || echo "[WARN] dist-upgrade 실패"
            echo "--- apt-get autoremove ---"
            sudo apt-get autoremove -y || true
            echo "--- uname -a ---"
            uname -a
            echo "--- lsb_release -a (가능하면) ---"
            lsb_release -a 2>/dev/null || echo "lsb_release not available"
            echo "===== SYSTEM UPGRADE END ====="
          } > "$UPG_LOG" 2>&1

          echo "::notice::시스템 업그레이드(패키지 최신화) 시도 완료. 상세 내용은 $UPG_LOG 참고."
          set -e

      #######################################################################
      # 1. 디렉토리 준비 + 구조 생성
      #######################################################################
      - name: 📂 디렉토리 생성 및 환경 초기화
        run: |
          set -e
          echo "디렉토리 구조 생성 중..."
          mkdir -p "${DATA_ROOT}"/{source_files,landing_zone,logs,archive,extract_out,tmp,quality,release}

          echo "생성된 디렉토리 확인:"
          ls -R "${DATA_ROOT}" || true

      #######################################################################
      # 1.5 가상 데이터 대량 생성 (landing_zone 에 대용량 CSV 생성)
      #
      #  - GEN_ROWS 만큼의 랜덤/유사랜덤 데이터를 생성
      #  - Teradata TPT가 빨아올 '원본 덤프' 역할
      #  - 실제 개인정보 아님 (전부 가짜 고객/가맹점/시간 정보)
      #
      # CSV 스키마:
      # COL1(고객ID 비슷), COL2(가맹점/메모), LOAD_TS(타임스탬프)
      #######################################################################
      - name: 🏗 가상 데이터 대량 생성 (GEN_ROWS=${{ env.GEN_ROWS }})
        run: |
          set -e
          SRC_FILE="${DATA_ROOT}/landing_zone/input_$(date +%Y%m%d).csv"
          ROWS="${GEN_ROWS}"

          echo "COL1,COL2,LOAD_TS" > "$SRC_FILE"

          # 간단한 의사난수 데이터 생성:
          #   COL1: 시퀀스 번호
          #   COL2: MERCHANT_xxx 혹은 NOTE_xxx 형태의 가상 거래 메모
          #   LOAD_TS: 현재 시간 기준
          #
          # 성능: seq는 빠르지만 echo 루프는 느릴 수 있음.
          # GEN_ROWS=500000도 깃허브 러너에서 수초~수십초 수준은 허용 가능.
          # 필요 시 줄여도 됨.
          echo "가상 데이터 ${ROWS}행 생성 중..."
          i=1
          while [ $i -le $ROWS ]; do
            # 간단 의사난수: $RANDOM (0~32767). merchant id 가짜
            MERCH=$(( (RANDOM % 9000) + 1000 ))
            echo "${i},MERCHANT_${MERCH}_NOTE_${i},$(date +%Y-%m-%dT%H:%M:%S%z)" >> "$SRC_FILE"
            i=$((i+1))
          done

          ls -lh "$SRC_FILE"
          head -n 5 "$SRC_FILE"
          tail -n 5 "$SRC_FILE"

          # 품질/검증용으로 row count를 기록해 둠
          echo "${ROWS}" > "${DATA_ROOT}/tmp/generated_rowcount.txt"
          echo "::notice::가상 CSV 생성 완료 (${ROWS} rows) -> $SRC_FILE"

      #######################################################################
      # 2. 환경 스냅샷 (보안/감사용 런타임 증빙)
      #######################################################################
      - name: 🔍 런타임 환경 스냅샷 저장
        run: |
          SNAP="${DATA_ROOT}/logs/env_snapshot.txt"
          {
            echo "===== ENV SNAPSHOT ====="
            date
            uname -a
            whoami
            echo "--- PATH ---"
            echo "$PATH"
            echo "--- DISK (df -h) ---"
            df -h
            echo "--- MEMORY (free -m) ---"
            free -m || true
            echo "--- GITHUB CONTEXT ---"
            echo "RUN_ID=$GITHUB_RUN_ID"
            echo "RUN_NUMBER=$GITHUB_RUN_NUMBER"
            echo "REPO=$GITHUB_REPOSITORY"
            echo "ACTOR=$GITHUB_ACTOR"
            echo "SHA=$GITHUB_SHA"
            echo "BRANCH=$GITHUB_REF_NAME"
          } > "$SNAP"
          echo "::debug::환경 스냅샷 기록 완료 -> $SNAP"

      #######################################################################
      # 3. DDL / TPT / 쿼리 정의 백업
      #    (각 서비스별 table & query 문서화)
      #######################################################################
      - name: 🧱 DDL/TPT/쿼리 스크립트 백업 (각 서비스별 table / query)
        run: |
          set -e
          mkdir -p "${DATA_ROOT}/source_files/sql"
          mkdir -p "${DATA_ROOT}/source_files/tpt"

          # 테이블 정의
          cat > "${DATA_ROOT}/source_files/sql/create_tables.sql" <<'SQL'
          -- [STAGING TABLE] (원천 덤프를 그대로 적재)
          CREATE TABLE STG_DATA (
            COL1       INTEGER,
            COL2       VARCHAR(100),
            LOAD_TS    TIMESTAMP,
            BATCH_ID   VARCHAR(40)
          );

          -- [FINAL TABLE] (정제/변환/중복제거 후 운영영역)
          CREATE TABLE FINAL_DATA (
            COL1       INTEGER,
            COL2       VARCHAR(100),
            LOAD_TS    TIMESTAMP,
            ETL_TS     TIMESTAMP,
            SRC_BATCH  VARCHAR(40)
          );

          -- [AUDIT TABLE] (배치 적재 이력/품질 검증 결과)
          CREATE TABLE LOAD_AUDIT_LOG (
            AUDIT_TS        TIMESTAMP,
            BATCH_ID        VARCHAR(40),
            SRC_FILE        VARCHAR(255),
            ROW_LOADED      INTEGER,
            ROW_EXPECTED    INTEGER,
            STATUS_CODE     INTEGER,
            STATUS_MESSAGE  VARCHAR(2000),
            OPERATOR        VARCHAR(128)
          );

          -- 인덱스 예시
          CREATE INDEX IDX_FINAL_DATA_COL1 ON FINAL_DATA (COL1);
          CREATE INDEX IDX_AUDIT_BATCH     ON LOAD_AUDIT_LOG (BATCH_ID);

          SQL

          # 병합/정제 프로시저 예시
          cat > "${DATA_ROOT}/source_files/sql/proc_LOAD_AND_MERGE.sql" <<'SQL'
          REPLACE PROCEDURE LOAD_AND_MERGE (
            IN p_batch_id VARCHAR(40),
            IN p_src_file VARCHAR(255)
          )
          BEGIN
            /* 1) STG_DATA -> FINAL_DATA 로 병합/정제 */
            INSERT INTO FINAL_DATA (COL1, COL2, LOAD_TS, ETL_TS, SRC_BATCH)
            SELECT
              COL1,
              TRIM(COL2),
              LOAD_TS,
              CURRENT_TIMESTAMP,
              p_batch_id
            FROM STG_DATA
            WHERE BATCH_ID = p_batch_id;

            /* 2) AUDIT LOG 에 이력 축적 */
            INSERT INTO LOAD_AUDIT_LOG (
              AUDIT_TS, BATCH_ID, SRC_FILE,
              ROW_LOADED, ROW_EXPECTED,
              STATUS_CODE, STATUS_MESSAGE, OPERATOR
            )
            VALUES (
              CURRENT_TIMESTAMP,
              p_batch_id,
              p_src_file,
              NULL,   -- 사후 UPDATE
              NULL,   -- 사후 UPDATE
              0,
              'LOAD_AND_MERGE executed',
              USER
            );
          END;
          SQL

          # Teradata TPT Bulk Load 템플릿
          cat > "${DATA_ROOT}/source_files/tpt/load_stg_data.tpt" <<'TPT'
          DEFINE JOB LOAD_STG_DATA
          (
            DEFINE SCHEMA STG_SCHEMA
            (
              COL1       INTEGER,
              COL2       VARCHAR(100),
              LOAD_TS    VARCHAR(30)
            );

            DEFINE OPERATOR FILE_READER
            TYPE DATACONNECTOR PRODUCER
            SCHEMA STG_SCHEMA
            ATTRIBUTES
            (
              FileName = '/home/runner/td_data/landing_zone/input_YYYYMMDD.csv',
              Format   = 'Delimited'
            );

            DEFINE OPERATOR TPT_INSERTER
            TYPE STREAM
            TARGET TABLE STG_DATA
            ATTRIBUTES
            (
              TdpId    = 'TERADATA_SID',
              UserName = 'ETL_USER',
              UserPassword = 'ETL_PASS',
              LogTable = 'ETL_LOG_TABLE'
            );

            APPLY
            (
              'INSERT INTO STG_DATA (COL1, COL2, LOAD_TS, BATCH_ID)
               VALUES (:COL1, :COL2, TIMESTAMP :LOAD_TS, ''BATCH_PLACEHOLDER'');'
            )
            TO OPERATOR (TPT_INSERTER[1])
            SELECT
              COL1, COL2, LOAD_TS
            FROM OPERATOR (FILE_READER[1]);
          );
          TPT

          # 품질 검증 / 통계 / 감사 조회 쿼리 모음
          cat > "${DATA_ROOT}/source_files/sql/quality_queries.sql" <<'SQL'
          -- 특정 배치에 대해 STG_DATA 적재 건수
          SELECT COUNT(*) AS CNT_STG
          FROM STG_DATA
          WHERE BATCH_ID = :BATCH_ID;

          -- 최종 FINAL_DATA 반영 건수
          SELECT COUNT(*) AS CNT_FINAL
          FROM FINAL_DATA
          WHERE SRC_BATCH = :BATCH_ID;

          -- 품질: 공백/NULL 메모 비율 등
          SELECT
            SUM(CASE WHEN COL2 IS NULL OR TRIM(COL2) = '' THEN 1 ELSE 0 END) AS NULL_MEMO_ROWS,
            COUNT(*) AS TOTAL_ROWS
          FROM FINAL_DATA
          WHERE SRC_BATCH = :BATCH_ID;

          -- 최근 AUDIT 로그 (배치별 최신 히스토리)
          SELECT *
          FROM LOAD_AUDIT_LOG
          QUALIFY ROW_NUMBER()
            OVER (PARTITION BY BATCH_ID ORDER BY AUDIT_TS DESC) = 1
          ORDER BY AUDIT_TS DESC;
          SQL

          echo "::notice::DDL/TPT/쿼리 스크립트가 ${DATA_ROOT}/source_files 에 저장되었습니다."
          ls -R "${DATA_ROOT}/source_files" || true

      #######################################################################
      # 4. 데이터 적재 & 병합 (실제 Teradata 동작 대신 시뮬)
      #    - 가상 대량 CSV를 TPT로 넣었다고 가정
      #    - LOAD_AND_MERGE 호출했다고 가정
      #    - 실패해도 파이프라인은 항상 계속 (continue-on-error)
      #    - 상태코드/행수 기록
      #######################################################################
      - name: 🔄 데이터 로드 및 변환/병합 실행 (대량 가상데이터 / 실패해도 계속)
        continue-on-error: true
        run: |
          set +e
          BATCH_ID="BATCH_$(date +%Y%m%d_%H%M%S)"
          SRC_FILE="${DATA_ROOT}/landing_zone/input_$(date +%Y%m%d).csv"
          PIPELINE_LOG="${DATA_ROOT}/logs/pipeline_load_merge.log"
          STATUS_FILE="${DATA_ROOT}/logs/pipeline_status.log"

          # 실제 Teradata라면:
          # 1) TPT 실행으로 ${SRC_FILE} -> ${TBL_STAGE}
          # 2) CALL LOAD_AND_MERGE(BATCH_ID, SRC_FILE);
          # 여기서는 시뮬레이션만 수행.

          GENERATED_COUNT=$(cat "${DATA_ROOT}/tmp/generated_rowcount.txt" 2>/dev/null || echo "${GEN_ROWS}")

          {
            echo "=== LOAD STAGE START ==="
            echo "BATCH_ID=$BATCH_ID"
            echo "SRC_FILE=$SRC_FILE"
            echo "TARGET_TABLE=${TARGET_TABLE}"
            echo "TBL_STAGE=${TBL_STAGE}, TBL_FINAL=${TBL_FINAL}, TBL_AUDIT=${TBL_AUDIT}"
            echo
            echo "[1] (시뮬) TPT Bulk Load ${GENERATED_COUNT}행 -> ${TBL_STAGE}"
            echo "    FROM ${SRC_FILE}"
            echo
            echo "[2] (시뮬) CALL LOAD_AND_MERGE('${BATCH_ID}','${SRC_FILE}')"
            echo "    ${TBL_STAGE} -> ${TBL_FINAL} 로 정제/병합 및 AUDIT 로깅"
            echo
            echo "[3] (시뮬) ${TBL_AUDIT} 에 감사 이력 insert"
            echo "=== LOAD STAGE END ==="
          } | tee "$PIPELINE_LOG"

          # 성공 가정 → STATUS_CODE=0
          STATUS_CODE=0
          STATUS_MSG="OK(vdata-bulk-load)"
          echo "STATUS_CODE=${STATUS_CODE}"        >  "$STATUS_FILE"
          echo "STATUS_MSG=${STATUS_MSG}"         >> "$STATUS_FILE"
          echo "BATCH_ID=${BATCH_ID}"             >> "$STATUS_FILE"
          echo "SRC_FILE=${SRC_FILE}"             >> "$STATUS_FILE"
          echo "ROW_EXPECTED=${EXPECTED_ROWCOUNT}" >> "$STATUS_FILE"
          echo "ROW_LOADED=${GENERATED_COUNT}"     >> "$STATUS_FILE"

          echo "::notice::데이터 적재/병합(대용량 가상 데이터) 단계 완료. 파이프라인은 계속됩니다."
          set -e

      #######################################################################
      # 5. 품질 검증 / QC 로그 생성
      #    - 기대 건수 vs 실제 건수 비교
      #    - NULL/이상데이터 등 기본 sanity check 결과
      #######################################################################
      - name: ✅ 품질 검증 및 QC 로그 생성
        run: |
          QUALITY_LOG="${DATA_ROOT}/quality/quality_check.log"
          STATUS_FILE="${DATA_ROOT}/logs/pipeline_status.log"

          EXPECTED="${EXPECTED_ROWCOUNT}"
          ACTUAL="$(grep '^ROW_LOADED=' \"$STATUS_FILE\" 2>/dev/null | cut -d= -f2)"
          if [ -z "$ACTUAL" ]; then
            ACTUAL="0"
          fi

          ROW_COUNT_OK="false"
          if [ "$EXPECTED" = "$ACTUAL" ]; then
            ROW_COUNT_OK="true"
          fi

          {
            echo "=== QUALITY CHECK ==="
            echo "TIMESTAMP=$(date +%Y-%m-%dT%H:%M:%S%z)"
            echo "EXPECTED_ROWCOUNT=$EXPECTED"
            echo "ACTUAL_ROWCOUNT=$ACTUAL"
            echo "ROW_COUNT_OK=$ROW_COUNT_OK"
            echo
            echo "--- PIPELINE STATUS SNAPSHOT ---"
            cat "$STATUS_FILE" 2>/dev/null || echo "NO STATUS_FILE"
            echo
            echo "--- SIMPLE SANITY RULES ---"
            echo "1) 적재 건수 기대치와 동일한가? -> $ROW_COUNT_OK"
            echo "2) (시뮬) NULL/공백 메모 레코드 비율은 HIGH하지 않은가? -> assumed OK"
          } > "$QUALITY_LOG"

          echo "::notice::품질 검증 로그 작성 완료 -> $QUALITY_LOG"
          head -n 50 "$QUALITY_LOG" || true

      #######################################################################
      # 6. 권한/접근제어 감사 기록 (ROLE/GRANT/REVOKE)
      #######################################################################
      - name: 🔐 권한/접근제어 감사 기록 생성
        run: |
          ACL_LOG="${DATA_ROOT}/logs/acl_audit.sql"
          {
            echo "-- 권한 감사 로그 (시뮬레이션)"
            echo "-- FINAL_DATA 조회/쓰기 권한 설정 예시"
            echo "GRANT SELECT ON ${TBL_FINAL} TO ROLE ANALYST_ROLE;"
            echo "GRANT INSERT,UPDATE ON ${TBL_FINAL} TO ROLE ETL_LOADER_ROLE;"
            echo "REVOKE INSERT ON ${TBL_FINAL} FROM ROLE ANALYST_ROLE;"
            echo
            echo "-- AUDIT LOG 테이블 접근 통제"
            echo "GRANT SELECT ON ${TBL_AUDIT} TO ROLE AUDIT_READER_ROLE;"
            echo
            echo "-- 실행 메타"
            echo "-- AUDIT_TS=$(date +%Y-%m-%dT%H:%M:%S%z)"
            echo "-- EXEC_BY=$GITHUB_ACTOR"
            echo "-- COMMIT_SHA=$GITHUB_SHA"
            echo "-- BRANCH=$GITHUB_REF_NAME"
          } > "$ACL_LOG"

          echo "::debug::권한 감사 로그 생성 완료 -> $ACL_LOG"
          head -n 40 "$ACL_LOG" || true

      #######################################################################
      # 7. 릴리즈 스냅샷 & 압축본 생성 (tar.gz)
      #    - 날짜+SHA 조합된 태그
      #######################################################################
      - name: 🗜 결과물 tar.gz 스냅샷 생성
        run: |
          SNAP_TAG="td-snapshot-$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA:0:8}"
          SNAP_DIR="${DATA_ROOT}/release"
          SNAP_FILE="${SNAP_DIR}/${SNAP_TAG}.tar.gz"

          echo "SNAP_TAG=$SNAP_TAG"    | tee "${DATA_ROOT}/logs/snapshot_tag.txt"
          echo "SNAP_FILE=$SNAP_FILE"  | tee -a "${DATA_ROOT}/logs/snapshot_tag.txt"

          mkdir -p "$SNAP_DIR"

          # 회계/정산본 느낌으로 남길 정보들 전부 묶음
          tar -czf "$SNAP_FILE" \
            -C "${DATA_ROOT}" \
            logs \
            quality \
            extract_out \
            source_files \
            landing_zone \
            tmp \
            || true

          echo "::notice::스냅샷 아카이브 생성 -> $SNAP_FILE"
          ls -lh "$SNAP_FILE" || true

      #######################################################################
      # 8. GitHub Release 업로드 시도 (옵션)
      #######################################################################
      - name: 🚀 GitHub Release(스냅샷) 업로드 시도
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          SNAP_INFO="${DATA_ROOT}/logs/snapshot_tag.txt"
          if [ -f "$SNAP_INFO" ]; then
            SNAP_TAG=$(grep '^SNAP_TAG=' "$SNAP_INFO" | cut -d= -f2)
            SNAP_FILE=$(grep '^SNAP_FILE=' "$SNAP_INFO" | cut -d= -f2)
          fi

          if [ -n "${SNAP_TAG:-}" ] && [ -f "${SNAP_FILE:-}" ]; then
            echo "::notice::릴리즈 태그 $SNAP_TAG, 파일 $SNAP_FILE 업로드 시도 중"
            gh release create "$SNAP_TAG" "$SNAP_FILE" \
              --title "$SNAP_TAG" \
              --notes "자동 Teradata 배치 스냅샷 (가상 대량데이터, 업그레이드 로그, 테이블/권한 정의, 품질검증, 감사로그 포함)" \
              || echo "::warning::gh release create 실패 (권한 부족 또는 태그 중복 가능)"
          else
            echo "::warning::스냅샷 정보가 없어 릴리즈 생략"
          fi

      #######################################################################
      # 9. 감사 요약 로그 (audit_run_summary.log)
      #    - 전체 실행 메타/상태/품질/스냅샷 경로 기록
      #######################################################################
      - name: 🧾 감사 요약 로그 생성 (audit_run_summary.log)
        run: |
          AUDIT_FILE="${DATA_ROOT}/logs/audit_run_summary.log"
          STATUS_FILE="${DATA_ROOT}/logs/pipeline_status.log"
          SNAP_INFO="${DATA_ROOT}/logs/snapshot_tag.txt"
          QUALITY_LOG="${DATA_ROOT}/quality/quality_check.log"
          UPG_LOG="${DATA_ROOT}/logs/system_upgrade.log"

          SNAP_TAG="N/A"
          SNAP_FILE="N/A"
          if [ -f "$SNAP_INFO" ]; then
            SNAP_TAG=$(grep '^SNAP_TAG=' "$SNAP_INFO" | cut -d= -f2)
            SNAP_FILE=$(grep '^SNAP_FILE=' "$SNAP_INFO" | cut -d= -f2)
          fi

          {
            echo "=== PIPELINE AUDIT SUMMARY ==="
            echo "TIMESTAMP=$(date +%Y-%m-%dT%H:%M:%S%z)"
            echo "ACTOR=$GITHUB_ACTOR"
            echo "REPO=$GITHUB_REPOSITORY"
            echo "BRANCH=$GITHUB_REF_NAME"
            echo "COMMIT_SHA=$GITHUB_SHA"
            echo
            echo "TARGET_TABLE=${TARGET_TABLE}"
            echo "TABLES_USED=${TBL_STAGE},${TBL_FINAL},${TBL_AUDIT}"
            echo "GEN_ROWS=${GEN_ROWS}"
            echo
            echo "--- STATUS_FILE ---"
            cat "$STATUS_FILE" 2>/dev/null || echo "(no pipeline_status.log)"
            echo
            echo "--- QUALITY_LOG ---"
            cat "$QUALITY_LOG" 2>/dev/null || echo "(no quality_check.log)"
            echo
            echo "--- SYSTEM UPGRADE LOG (요약 앞부분 60줄) ---"
            head -n 60 "$UPG_LOG" 2>/dev/null || echo "(no system_upgrade.log)"
            echo
            echo "--- SNAPSHOT INFO ---"
            echo "SNAP_TAG=$SNAP_TAG"
            echo "SNAP_FILE=$SNAP_FILE"
            echo "DATA_ROOT=$DATA_ROOT"
          } > "$AUDIT_FILE"

          echo "::notice::감사 요약 로그 생성 완료 -> $AUDIT_FILE"
          head -n 200 "$AUDIT_FILE" || true

      #######################################################################
      # 10. Artifact 업로드 (로그/DDL/스냅샷/가상데이터)
      #######################################################################
      - name: 📦 실행 산출물 업로드 (logs / quality / source / snapshot 등)
        uses: actions/upload-artifact@v4
        with:
          name: teradata-run-${{ github.run_id }}
          path: |
            ${{ env.DATA_ROOT }}/logs/**
            ${{ env.DATA_ROOT }}/quality/**
            ${{ env.DATA_ROOT }}/source_files/**
            ${{ env.DATA_ROOT }}/release/**
            ${{ env.DATA_ROOT }}/landing_zone/**
            ${{ env.DATA_ROOT }}/extract_out/**
            ${{ env.DATA_ROOT }}/tmp/**
          if-no-files-found: warn
          retention-days: 14

      #######################################################################
      # 11. 최종 종료 (항상 성공으로 종료)
      #######################################################################
      - name: ✅ 파이프라인 완료 (항상 성공)
        if: always()
        run: |
          echo "✅ Teradata FinOps Batch 파이프라인 전체 단계 수행 완료."
          echo "   - 시스템 업그레이드 로그 기록"
          echo "   - 대량 가상데이터(${GEN_ROWS} rows) 생성 및 적재 시뮬"
          echo "   - 테이블/권한/품질/감사/스냅샷 전부 산출물화"
          echo "   - tar.gz 스냅샷 + (옵션) Release 업로드"
          echo "   - audit_run_summary.log, quality_check.log, pipeline_status.log 등 추적 가능 로그 생성"
          echo "모든 산출물이 artifact teradata-run-${GITHUB_RUN_ID} 로 업로드되었습니다."
          exit 0
