name: "ğŸ¦ Teradata FinOps Batch â€” EchoOps + Audit + Snapshot + Schedule (ë§Œì „ëŒ€ë¹„)"

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:
  schedule:
    # ë§¤ì¼ 15:30 UTC == í•œêµ­ì‹œê°„(KST) ìƒˆë²½ 00:30 ìë™ ì•¼ê°„ë°°ì¹˜
    - cron: "30 15 * * *"

permissions:
  contents: write   # ìŠ¤ëƒ…ìƒ· tar.gzë¥¼ GitHub Release ë¡œ ì˜¬ë¦´ ìˆ˜ ìˆê²Œ ì¤€ë¹„

env:
  # ê³µí†µ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (ë°ì´í„°/ë¡œê·¸/ì‚°ì¶œë¬¼ ëª¨ë‘ ì €ì¥)
  DATA_ROOT: /home/runner/td_data

  # ì„œë¹„ìŠ¤/ë„ë©”ì¸ë³„ í…Œì´ë¸” ëŒ€ìƒ (Staging -> Final -> Audit ì‹ íŒŒì´í”„ë¼ì¸ ê°€ì •)
  TBL_STAGE: STG_DATA
  TBL_FINAL: FINAL_DATA
  TBL_AUDIT: LOAD_AUDIT_LOG

  # ê¸°ë³¸ ë³‘í•© íƒ€ê¹ƒ
  TARGET_TABLE: FINAL_DATA

  # í’ˆì§ˆ ê¸°ëŒ€ í–‰ìˆ˜ (ì˜ˆ: ì¼ì¼ ì ì¬ 500,000ê±´)
  EXPECTED_ROWCOUNT: "500000"

jobs:
  teradata_pipeline_job:
    runs-on: ubuntu-latest

    steps:
      #######################################################################
      # 0. ì½”ë“œ ì²´í¬ì•„ì›ƒ + ì‹œì‘ ì•Œë¦¼
      #######################################################################
      - name: ğŸ“¥ ì½”ë“œ ì²´í¬ì•„ì›ƒ
        uses: actions/checkout@v4

      - name: ğŸ“ ì›Œí¬í”Œë¡œìš° ì‹œì‘ ë¡œê¹…
        run: |
          echo "::notice::Teradata í†µí•© ì›Œí¬í”Œë¡œìš°(ì•¼ê°„ë°°ì¹˜/ìˆ˜ë™ì‹¤í–‰/Push)ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
          echo "::debug::DATA_ROOT=${DATA_ROOT}, TARGET_TABLE=${TARGET_TABLE}"

      #######################################################################
      # 1. ë””ë ‰í† ë¦¬ ì¤€ë¹„ + êµ¬ì¡° ìƒì„± (logs, archive, landing_zone ë“±)
      #######################################################################
      - name: ğŸ“‚ ë””ë ‰í† ë¦¬ ìƒì„± ë° í™˜ê²½ ì´ˆê¸°í™”
        run: |
          set -e
          echo "ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘..."
          mkdir -p "${DATA_ROOT}"/{source_files,landing_zone,logs,archive,extract_out,tmp,quality,release}

          echo "ìƒì„±ëœ ë””ë ‰í† ë¦¬ í™•ì¸:"
          ls -R "${DATA_ROOT}" || true

          # ë°°ì¹˜ ì…ë ¥ ì›ë³¸(landing_zone) ì‹œë®¬ë ˆì´ì…˜ CSV ë”ë¯¸ë„ ìƒì„±
          SAMPLE_SRC="${DATA_ROOT}/landing_zone/input_$(date +%Y%m%d).csv"
          echo "COL1,COL2,LOAD_TS"          >  "$SAMPLE_SRC"
          echo "1,Hello,$(date +%F' '%T)"   >> "$SAMPLE_SRC"
          echo "2,World,$(date +%F' '%T)"   >> "$SAMPLE_SRC"
          echo "ìƒ˜í”Œ ì ì¬ ëŒ€ìƒ CSV: $SAMPLE_SRC"

      #######################################################################
      # 2. í™˜ê²½ ìŠ¤ëƒ…ìƒ· (ë³´ì•ˆ/ê°ì‚¬ìš© ëŸ°íƒ€ì„ ì¦ë¹™)
      #######################################################################
      - name: ğŸ” ëŸ°íƒ€ì„ í™˜ê²½ ìŠ¤ëƒ…ìƒ· ì €ì¥
        run: |
          SNAP="${DATA_ROOT}/logs/env_snapshot.txt"
          {
            echo "===== ENV SNAPSHOT ====="
            date
            uname -a
            whoami
            echo "--- PATH ---"
            echo "$PATH"
            echo "--- DISK (df -h) ---"
            df -h
            echo "--- MEMORY (free -m) ---"
            free -m || true
            echo "--- GITHUB CONTEXT ---"
            echo "RUN_ID=$GITHUB_RUN_ID"
            echo "RUN_NUMBER=$GITHUB_RUN_NUMBER"
            echo "REPO=$GITHUB_REPOSITORY"
            echo "ACTOR=$GITHUB_ACTOR"
            echo "SHA=$GITHUB_SHA"
            echo "BRANCH=$GITHUB_REF_NAME"
          } > "$SNAP"
          echo "::debug::í™˜ê²½ ìŠ¤ëƒ…ìƒ· ê¸°ë¡ ì™„ë£Œ -> $SNAP"

      #######################################################################
      # 3. DDL / TPT / ì„œë¹„ìŠ¤ ë¡œì§ ë°±ì—…
      #    - ì„œë¹„ìŠ¤ë³„ í…Œì´ë¸” ì •ì˜ (STG_DATA, FINAL_DATA, LOAD_AUDIT_LOG ë“±)
      #    - ë³‘í•©/ì ì¬ í”„ë¡œì‹œì €
      #    - TPT Bulk Load ìŠ¤í¬ë¦½íŠ¸
      #    - í’ˆì§ˆê²€ì¦ìš© SELECT ì¿¼ë¦¬
      #######################################################################
      - name: ğŸ§± DDL/TPT/ì¿¼ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ë°±ì—… (ê° ì„œë¹„ìŠ¤ë³„ table / query ê¸°ë¡)
        run: |
          set -e
          mkdir -p "${DATA_ROOT}/source_files/sql"
          mkdir -p "${DATA_ROOT}/source_files/tpt"

          # 3-1. ìŠ¤í…Œì´ì§•(STG_DATA), ê²°ê³¼(FINAL_DATA), ê°ì‚¬ë¡œê·¸(LOAD_AUDIT_LOG) í…Œì´ë¸” ìƒì„± ìŠ¤í¬ë¦½íŠ¸
          cat > "${DATA_ROOT}/source_files/sql/create_tables.sql" <<'SQL'
          -- [STAGING TABLE] ì›ì²œ ì ì¬ (ì›ë³¸ ê·¸ëŒ€ë¡œ/ìµœì†Œ ê°€ê³µ)
          CREATE TABLE STG_DATA (
            COL1       INTEGER,
            COL2       VARCHAR(100),
            LOAD_TS    TIMESTAMP,
            BATCH_ID   VARCHAR(40)
          );

          -- [FINAL TABLE] ì •ì œ/ë³€í™˜/ì¤‘ë³µ ì œê±° í›„ ìš´ì˜ìš© í…Œì´ë¸”
          CREATE TABLE FINAL_DATA (
            COL1       INTEGER,
            COL2       VARCHAR(100),
            LOAD_TS    TIMESTAMP,
            ETL_TS     TIMESTAMP,
            SRC_BATCH  VARCHAR(40)
          );

          -- [AUDIT TABLE] ì ì¬/ë³‘í•© ì´ë ¥, í’ˆì§ˆ, ì„±ê³µ/ì‹¤íŒ¨ ìƒíƒœ ë¡œê·¸
          CREATE TABLE LOAD_AUDIT_LOG (
            AUDIT_TS        TIMESTAMP,
            BATCH_ID        VARCHAR(40),
            SRC_FILE        VARCHAR(255),
            ROW_LOADED      INTEGER,
            ROW_EXPECTED    INTEGER,
            STATUS_CODE     INTEGER,
            STATUS_MESSAGE  VARCHAR(2000),
            OPERATOR        VARCHAR(128)
          );

          -- ì¸ë±ìŠ¤ ì˜ˆì‹œ
          CREATE INDEX IDX_FINAL_DATA_COL1 ON FINAL_DATA (COL1);
          CREATE INDEX IDX_AUDIT_BATCH     ON LOAD_AUDIT_LOG (BATCH_ID);

          SQL

          # 3-2. ë³‘í•©/ì •ì œ í”„ë¡œì‹œì € (LOAD_AND_MERGE)
          cat > "${DATA_ROOT}/source_files/sql/proc_LOAD_AND_MERGE.sql" <<'SQL'
          REPLACE PROCEDURE LOAD_AND_MERGE (
            IN p_batch_id VARCHAR(40),
            IN p_src_file VARCHAR(255)
          )
          BEGIN
            /* 1) STG_DATA -> FINAL_DATA ë¡œ ë³‘í•©/ì •ì œ í›„ ì‚½ì… */
            INSERT INTO FINAL_DATA (COL1, COL2, LOAD_TS, ETL_TS, SRC_BATCH)
            SELECT
              COL1,
              TRIM(COL2),
              LOAD_TS,
              CURRENT_TIMESTAMP,
              p_batch_id
            FROM STG_DATA
            WHERE BATCH_ID = p_batch_id;

            /* 2) ê°ì‚¬ë¡œê·¸ ë‚¨ê¸°ê¸° (ROW_LOADED ë“±ì€ ì‚¬í›„ UPDATEì—ì„œ ì…ë ¥ ê°€ëŠ¥) */
            INSERT INTO LOAD_AUDIT_LOG (
              AUDIT_TS, BATCH_ID, SRC_FILE, ROW_LOADED, ROW_EXPECTED,
              STATUS_CODE, STATUS_MESSAGE, OPERATOR
            ) VALUES (
              CURRENT_TIMESTAMP,
              p_batch_id,
              p_src_file,
              NULL,
              NULL,
              0,
              'LOAD_AND_MERGE executed',
              USER
            );

          END;
          SQL

          # 3-3. Teradata TPT (ëŒ€ëŸ‰ ì ì¬) ì˜ˆì‹œ
          cat > "${DATA_ROOT}/source_files/tpt/load_stg_data.tpt" <<'TPT'
          DEFINE JOB LOAD_STG_DATA
          (
            DEFINE SCHEMA STG_SCHEMA
            (
              COL1       INTEGER,
              COL2       VARCHAR(100),
              LOAD_TS    VARCHAR(30)
            );

            DEFINE OPERATOR FILE_READER
            TYPE DATACONNECTOR PRODUCER
            SCHEMA STG_SCHEMA
            ATTRIBUTES
            (
              FileName = '/home/runner/td_data/landing_zone/input_YYYYMMDD.csv',
              Format   = 'Delimited'
            );

            DEFINE OPERATOR TPT_INSERTER
            TYPE STREAM
            TARGET TABLE STG_DATA
            ATTRIBUTES
            (
              TdpId    = 'TERADATA_SID',
              UserName = 'ETL_USER',
              UserPassword = 'ETL_PASS',
              LogTable = 'ETL_LOG_TABLE'
            );

            APPLY
            (
              'INSERT INTO STG_DATA (COL1, COL2, LOAD_TS, BATCH_ID)
               VALUES (:COL1, :COL2, TIMESTAMP :LOAD_TS, ''BATCH_PLACEHOLDER'');'
            )
            TO OPERATOR (TPT_INSERTER[1])
            SELECT
              COL1, COL2, LOAD_TS
            FROM OPERATOR (FILE_READER[1]);
          );
          TPT

          # 3-4. í’ˆì§ˆ ê²€ì¦/í†µê³„ìš© ì¿¼ë¦¬ (ì„œë¹„ìŠ¤ë³„ ì¡°íšŒ ì˜ˆì‹œ)
          cat > "${DATA_ROOT}/source_files/sql/quality_queries.sql" <<'SQL'
          -- ì ì¬ëœ STG_DATA ê±´ìˆ˜
          SELECT COUNT(*) AS CNT_STG
          FROM STG_DATA
          WHERE BATCH_ID = :BATCH_ID;

          -- ìµœì¢… ë°˜ì˜ëœ FINAL_DATA ê±´ìˆ˜
          SELECT COUNT(*) AS CNT_FINAL
          FROM FINAL_DATA
          WHERE SRC_BATCH = :BATCH_ID;

          -- ìµœì¢… í…Œì´ë¸”ì—ì„œ NULL/ë¹„ì–´ìˆëŠ” COL2 ì¡´ì¬ ìœ ë¬´ ì²´í¬
          SELECT COUNT(*) AS NULL_COL2_ROWS
          FROM FINAL_DATA
          WHERE (COL2 IS NULL OR TRIM(COL2) = '');

          -- ìµœê·¼ ì ì¬ AUDIT LOG
          SELECT *
          FROM LOAD_AUDIT_LOG
          ORDER BY AUDIT_TS DESC
          QUALIFY ROW_NUMBER() OVER (PARTITION BY BATCH_ID ORDER BY AUDIT_TS DESC) = 1;
          SQL

          echo "::notice::DDL/TPT/ì¿¼ë¦¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ${DATA_ROOT}/source_files ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
          ls -R "${DATA_ROOT}/source_files" || true

      #######################################################################
      # 4. ë°ì´í„° ì ì¬ & ë³‘í•© (continue-on-error; status ê¸°ë¡)
      #    - TPT Bulk Load ì‹œë®¬ë ˆì´ì…˜
      #    - SP(LOAD_AND_MERGE) í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
      #    - ì‹¤íŒ¨í•´ë„ íŒŒì´í”„ë¼ì¸ì€ ê³„ì†
      #######################################################################
      - name: ğŸ”„ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜/ë³‘í•© ì‹¤í–‰ (ì‹¤íŒ¨í•´ë„ ê³„ì†)
        continue-on-error: true
        run: |
          set +e

          BATCH_ID="BATCH_$(date +%Y%m%d_%H%M%S)"
          SRC_FILE="${DATA_ROOT}/landing_zone/input_$(date +%Y%m%d).csv"

          PIPELINE_LOG="${DATA_ROOT}/logs/pipeline_load_merge.log"
          STATUS_FILE="${DATA_ROOT}/logs/pipeline_status.log"

          {
            echo "=== LOAD STAGE START ==="
            echo "BATCH_ID=$BATCH_ID"
            echo "SRC_FILE=$SRC_FILE"
            echo "TARGET_TABLE=${TARGET_TABLE}"
            echo "TBL_STAGE=${TBL_STAGE}, TBL_FINAL=${TBL_FINAL}, TBL_AUDIT=${TBL_AUDIT}"
            echo
            echo "[1] TPT Bulk Load ì‹œë®¬ë ˆì´ì…˜ â†’ ${TBL_STAGE}"
            echo "    (${SRC_FILE} -> ${TBL_STAGE})"
            echo "    í–‰ ìˆ˜ ê°€ì •: ${EXPECTED_ROWCOUNT}í–‰ ì ì¬"
            echo
            echo "[2] ì €ì¥ í”„ë¡œì‹œì € LOAD_AND_MERGE('${BATCH_ID}','${SRC_FILE}') ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜"
            echo "    ${TBL_STAGE} -> ${TBL_FINAL} ë¡œ ì •ì œ/ë³‘í•©"
            echo
            echo "[3] ê°ì‚¬ í…Œì´ë¸” ${TBL_AUDIT} ì— ì ì¬ ì´ë ¥ insert ê°€ì •"
            echo "=== LOAD STAGE END ==="
          } | tee "$PIPELINE_LOG"

          # ì ì¬/ë³‘í•©ì´ 'ì„±ê³µ'í–ˆë‹¤ê³  ê°€ì •í•˜ê³  exit code = 0ìœ¼ë¡œ ê¸°ë¡
          STATUS_CODE=0
          STATUS_MSG="OK"
          echo "STATUS_CODE=${STATUS_CODE}"     >  "$STATUS_FILE"
          echo "STATUS_MSG=${STATUS_MSG}"       >> "$STATUS_FILE"
          echo "BATCH_ID=${BATCH_ID}"           >> "$STATUS_FILE"
          echo "SRC_FILE=${SRC_FILE}"           >> "$STATUS_FILE"
          echo "ROW_EXPECTED=${EXPECTED_ROWCOUNT}" >> "$STATUS_FILE"
          echo "ROW_LOADED=${EXPECTED_ROWCOUNT}"   >> "$STATUS_FILE"

          echo "::notice::ë°ì´í„° ì ì¬/ë³‘í•© ë‹¨ê³„ ìˆ˜í–‰ ì™„ë£Œ(ì‹œë®¬ë ˆì´íŠ¸). íŒŒì´í”„ë¼ì¸ì€ í•­ìƒ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤."
          set -e

      #######################################################################
      # 5. í’ˆì§ˆ ê²€ì¦ ë¡œê·¸ (ê¸°ëŒ€ í–‰ìˆ˜ vs ì‹¤ì œ í–‰ìˆ˜ ë“± QC ì§€í‘œ)
      #    - ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” DBì—ì„œ COUNT(*) ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ì§€ë§Œ
      #      ì§€ê¸ˆì€ ì‹œë®¬ë ˆì´ì…˜ ê°’(EXPECTED_ROWCOUNT)ìœ¼ë¡œ ê¸°ë¡
      #######################################################################
      - name: âœ… í’ˆì§ˆ ê²€ì¦ ë° QC ë¡œê·¸ ìƒì„±
        run: |
          QUALITY_LOG="${DATA_ROOT}/quality/quality_check.log"
          STATUS_FILE="${DATA_ROOT}/logs/pipeline_status.log"

          EXPECTED="${EXPECTED_ROWCOUNT}"
          ACTUAL="${EXPECTED_ROWCOUNT}"

          ROW_COUNT_OK="false"
          if [ "$EXPECTED" = "$ACTUAL" ]; then
            ROW_COUNT_OK="true"
          fi

          {
            echo "=== QUALITY CHECK ==="
            echo "TIMESTAMP=$(date +%Y-%m-%dT%H:%M:%S%z)"
            echo "EXPECTED_ROWCOUNT=$EXPECTED"
            echo "ACTUAL_ROWCOUNT=$ACTUAL"
            echo "ROW_COUNT_OK=$ROW_COUNT_OK"
            echo
            echo "--- PIPELINE STATUS SNAPSHOT ---"
            cat "$STATUS_FILE" 2>/dev/null || echo "NO STATUS_FILE"
          } > "$QUALITY_LOG"

          echo "::notice::í’ˆì§ˆ ê²€ì¦ ë¡œê·¸ ì‘ì„± ì™„ë£Œ -> $QUALITY_LOG"
          cat "$QUALITY_LOG" || true

      #######################################################################
      # 6. ê¶Œí•œ/ì ‘ê·¼ì œì–´ ê°ì‚¬ ê¸°ë¡ (ROLEë³„ ê¶Œí•œ ë³€í™”ë„ ì¦ë¹™)
      #######################################################################
      - name: ğŸ” ê¶Œí•œ/ì ‘ê·¼ì œì–´ ê°ì‚¬ ê¸°ë¡ ìƒì„±
        run: |
          ACL_LOG="${DATA_ROOT}/logs/acl_audit.sql"
          {
            echo "-- ê¶Œí•œ ê°ì‚¬ ë¡œê·¸ (ì‹œë®¬ë ˆì´ì…˜)"
            echo "-- FINAL_DATA ì¡°íšŒê¶Œ/ì“°ê¸°ê¶Œ ë“± ì—­í• ë³„ ê¶Œí•œ"
            echo "GRANT SELECT ON ${TBL_FINAL} TO ROLE ANALYST_ROLE;"
            echo "GRANT INSERT,UPDATE ON ${TBL_FINAL} TO ROLE ETL_LOADER_ROLE;"
            echo "REVOKE INSERT ON ${TBL_FINAL} FROM ROLE ANALYST_ROLE;"
            echo
            echo "-- ê°ì‚¬ í…Œì´ë¸” LOAD_AUDIT_LOG ì— ëŒ€í•œ ì ‘ê·¼ ì œì–´"
            echo "GRANT SELECT ON ${TBL_AUDIT} TO ROLE AUDIT_READER_ROLE;"
            echo
            echo "-- ì‹¤í–‰ ì‹œê° ë° ì‹¤í–‰ì ê¸°ë¡"
            echo "-- AUDIT_TS=$(date +%Y-%m-%dT%H:%M:%S%z)"
            echo "-- EXEC_BY=${GITHUB_ACTOR}"
            echo "-- COMMIT_SHA=${GITHUB_SHA}"
            echo "-- BRANCH=${GITHUB_REF_NAME}"
          } > "$ACL_LOG"

          echo "::debug::ê¶Œí•œ ê°ì‚¬ ë¡œê·¸ ìƒì„± ì™„ë£Œ -> $ACL_LOG"
          cat "$ACL_LOG" || true

      #######################################################################
      # 7. ë¦´ë¦¬ì¦ˆ ìŠ¤ëƒ…ìƒ· & ì••ì¶•ë³¸ ìƒì„± (tar.gz)
      #    - ë‚ ì§œ+SHA ê¸°ë°˜ íŒŒì¼ ì´ë¦„
      #    - ì´ tar.gzëŠ” íšŒê³„/ì •ì‚°ë³¸ì²˜ëŸ¼ ë³´ê´€ ê°€ëŠ¥
      #######################################################################
      - name: ğŸ—œ ê²°ê³¼ë¬¼ tar.gz ìŠ¤ëƒ…ìƒ· ìƒì„±
        run: |
          SNAP_TAG="td-snapshot-$(date +%Y%m%d-%H%M%S)-${GITHUB_SHA:0:8}"
          SNAP_DIR="${DATA_ROOT}/release"
          SNAP_FILE="${SNAP_DIR}/${SNAP_TAG}.tar.gz"

          echo "SNAP_TAG=$SNAP_TAG"    | tee "${DATA_ROOT}/logs/snapshot_tag.txt"
          echo "SNAP_FILE=$SNAP_FILE"  | tee -a "${DATA_ROOT}/logs/snapshot_tag.txt"

          mkdir -p "$SNAP_DIR"

          tar -czf "$SNAP_FILE" \
            -C "${DATA_ROOT}" \
            logs \
            quality \
            extract_out \
            source_files \
            landing_zone \
            || true

          echo "::notice::ìŠ¤ëƒ…ìƒ· ì•„ì¹´ì´ë¸Œ ìƒì„± -> $SNAP_FILE"
          ls -lh "$SNAP_FILE" || true

      #######################################################################
      # 8. GitHub Release ì—…ë¡œë“œ (ì„ íƒ) - ì‹¤íŒ¨í•´ë„ ì›Œí¬í”Œë¡œìš°ëŠ” ê³„ì†
      #    - gh CLIëŠ” ubuntu-latest ëŸ¬ë„ˆì— ê¸°ë³¸ ì„¤ì¹˜ë˜ì–´ ìˆìŒ
      #    - private repoì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥ (permissions.contents: write í•„ìš”)
      #    - ë‚´ë¶€ìš© "ì¬ë¬´ ë§ˆê°ë³¸"ì²˜ëŸ¼ ë¦´ë¦¬ì¦ˆë¡œ ë‚¨ê¸°ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
      #######################################################################
      - name: ğŸš€ GitHub Release(ìŠ¤ëƒ…ìƒ·) ì—…ë¡œë“œ ì‹œë„
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          SNAP_INFO="${DATA_ROOT}/logs/snapshot_tag.txt"
          if [ -f "$SNAP_INFO" ]; then
            SNAP_TAG=$(grep '^SNAP_TAG=' "$SNAP_INFO" | cut -d= -f2)
            SNAP_FILE=$(grep '^SNAP_FILE=' "$SNAP_INFO" | cut -d= -f2)
          fi

          if [ -n "${SNAP_TAG:-}" ] && [ -f "${SNAP_FILE:-}" ]; then
            echo "::notice::ë¦´ë¦¬ì¦ˆ íƒœê·¸ $SNAP_TAG, íŒŒì¼ $SNAP_FILE ì—…ë¡œë“œ ì‹œë„ ì¤‘"
            gh release create "$SNAP_TAG" "$SNAP_FILE" \
              --title "$SNAP_TAG" \
              --notes "ìë™ Teradata ë°°ì¹˜ ìŠ¤ëƒ…ìƒ· (í…Œì´ë¸”ì •ì˜/ACL/í’ˆì§ˆë¡œê·¸/í™˜ê²½ìŠ¤ëƒ…ìƒ· í¬í•¨)" \
              || echo "::warning::gh release create ì‹¤íŒ¨ (ê¶Œí•œ ë˜ëŠ” ê¸°ì¡´ íƒœê·¸ ì¤‘ë³µ ê°€ëŠ¥)"
          else
            echo "::warning::ìŠ¤ëƒ…ìƒ· ì •ë³´ê°€ ì—†ì–´ ë¦´ë¦¬ì¦ˆ ìƒëµ"
          fi

      #######################################################################
      # 9. ê°ì‚¬ ìš”ì•½ ë¡œê·¸ (audit_run_summary.log)
      #    - ëˆ„ê°€ ëŒë ¸ëŠ”ì§€ / ì–´ë–¤ ë°°ì¹˜ì¸ì§€ / í’ˆì§ˆê²°ê³¼ / ìƒíƒœì½”ë“œ / ìŠ¤ëƒ…ìƒ· íƒœê·¸
      #######################################################################
      - name: ğŸ§¾ ê°ì‚¬ ìš”ì•½ ë¡œê·¸ ìƒì„± (audit_run_summary.log)
        run: |
          AUDIT_FILE="${DATA_ROOT}/logs/audit_run_summary.log"
          STATUS_FILE="${DATA_ROOT}/logs/pipeline_status.log"
          SNAP_INFO="${DATA_ROOT}/logs/snapshot_tag.txt"
          QUALITY_LOG="${DATA_ROOT}/quality/quality_check.log"

          SNAP_TAG="N/A"
          SNAP_FILE="N/A"
          if [ -f "$SNAP_INFO" ]; then
            SNAP_TAG=$(grep '^SNAP_TAG=' "$SNAP_INFO" | cut -d= -f2)
            SNAP_FILE=$(grep '^SNAP_FILE=' "$SNAP_INFO" | cut -d= -f2)
          fi

          {
            echo "=== PIPELINE AUDIT SUMMARY ==="
            echo "TIMESTAMP=$(date +%Y-%m-%dT%H:%M:%S%z)"
            echo "ACTOR=$GITHUB_ACTOR"
            echo "REPO=$GITHUB_REPOSITORY"
            echo "BRANCH=$GITHUB_REF_NAME"
            echo "COMMIT_SHA=$GITHUB_SHA"
            echo "TARGET_TABLE=${TARGET_TABLE}"
            echo "TABLES_USED=${TBL_STAGE},${TBL_FINAL},${TBL_AUDIT}"
            echo "--- STATUS_FILE ---"
            cat "$STATUS_FILE"   2>/dev/null || echo "(no pipeline_status.log)"
            echo
            echo "--- QUALITY_LOG ---"
            cat "$QUALITY_LOG"   2>/dev/null || echo "(no quality_check.log)"
            echo
            echo "--- SNAPSHOT INFO ---"
            echo "SNAP_TAG=$SNAP_TAG"
            echo "SNAP_FILE=$SNAP_FILE"
            echo "DATA_ROOT=$DATA_ROOT"
          } > "$AUDIT_FILE"

          echo "::notice::ê°ì‚¬ ìš”ì•½ ë¡œê·¸ ìƒì„± ì™„ë£Œ -> $AUDIT_FILE"
          cat "$AUDIT_FILE" || true

      #######################################################################
      # 10. Artifact ì—…ë¡œë“œ (logs / quality / source_files / release)
      #     - ê·œì œ/ì¶”ì /ì¬í˜„ ê°€ëŠ¥í•˜ë„ë¡ ì „ì²´ ì‚°ì¶œë¬¼ ë³´ì¡´
      #######################################################################
      - name: ğŸ“¦ ì‹¤í–‰ ì‚°ì¶œë¬¼ ì—…ë¡œë“œ (logs / quality / source / snapshot ë“±)
        uses: actions/upload-artifact@v4
        with:
          name: teradata-run-${{ github.run_id }}
          path: |
            ${{ env.DATA_ROOT }}/logs/**
            ${{ env.DATA_ROOT }}/quality/**
            ${{ env.DATA_ROOT }}/source_files/**
            ${{ env.DATA_ROOT }}/release/**
            ${{ env.DATA_ROOT }}/landing_zone/**
            ${{ env.DATA_ROOT }}/extract_out/**
          if-no-files-found: warn
          retention-days: 14

      #######################################################################
      # 11. ìµœì¢… ë§ˆë¬´ë¦¬ (í•­ìƒ ì„±ê³µìœ¼ë¡œ ì¢…ë£Œ)
      #######################################################################
      - name: âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (í•­ìƒ ì„±ê³µ)
        if: always()
        run: |
          echo "âœ… Teradata FinOps Batch íŒŒì´í”„ë¼ì¸ ì „ì²´ ë‹¨ê³„ ìˆ˜í–‰ ì™„ë£Œ."
          echo "   - ë””ë ‰í† ë¦¬ ì¤€ë¹„"
          echo "   - í™˜ê²½ ìŠ¤ëƒ…ìƒ·"
          echo "   - DDL/TPT/ì¿¼ë¦¬ ë°±ì—…"
          echo "   - ì ì¬/ë³‘í•© (continue-on-error)"
          echo "   - í’ˆì§ˆê²€ì¦ ë¡œê·¸"
          echo "   - ê¶Œí•œ ê°ì‚¬ ê¸°ë¡"
          echo "   - tar.gz ìŠ¤ëƒ…ìƒ· + (ì˜µì…˜) Release ì‹œë„"
          echo "   - audit_run_summary.log ìƒì„±"
          echo "   - artifact ì—…ë¡œë“œ"
          echo "ëª¨ë“  ì‚°ì¶œë¬¼ì´ artifact teradata-run-${GITHUB_RUN_ID} ë¡œ ë³´ê´€ë©ë‹ˆë‹¤."
          exit 0
